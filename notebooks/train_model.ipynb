{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent Core - 模型训练 Notebook\n",
    "\n",
    "本Notebook用于训练AI Agent所需的模型组件。\n",
    "\n",
    "**GitHub仓库**: 请修改下方的 `GITHUB_REPO` 变量为你的仓库地址"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 配置区 ====================\n",
    "# 请修改以下参数\n",
    "\n",
    "# GitHub仓库地址 (修改为你的仓库)\n",
    "GITHUB_REPO = \"https://github.com/your-username/ai-agent-core.git\"\n",
    "\n",
    "# Hugging Face配置\n",
    "HF_TOKEN = \"\"  # 你的HF token (可选)\n",
    "HF_REPO_ID = \"your-username/ai-agent-model\"  # 上传目标仓库 (可选)\n",
    "\n",
    "# 模型配置\n",
    "BASE_MODEL = \"Qwen/Qwen2.5-7B-Instruct\"  # 基础模型\n",
    "\n",
    "# 训练配置\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-4\n",
    "MAX_LENGTH = 2048\n",
    "\n",
    "# LoRA配置\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "\n",
    "# ==================== 配置结束 ====================\n",
    "\n",
    "print(\"配置参数已设置!\")\n",
    "print(f\"GitHub仓库: {GITHUB_REPO}\")\n",
    "print(f\"基础模型: {BASE_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖\n",
    "print(\"安装依赖中...\")\n",
    "\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q transformers datasets accelerate peft bitsandbytes trl\n",
    "!pip install -q wandb tensorboard\n",
    "!pip install -q qdrant-client pgvector psycopg2-binary\n",
    "!pip install -q fastapi uvicorn pydantic pydantic-settings httpx sqlalchemy asyncpg redis\n",
    "\n",
    "print(\"依赖安装完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 克隆项目\n",
    "import os\n",
    "\n",
    "PROJECT_DIR = \"/content/ai-agent-core\"\n",
    "\n",
    "if not os.path.exists(PROJECT_DIR):\n",
    "    print(f\"克隆项目: {GITHUB_REPO}\")\n",
    "    !git clone {GITHUB_REPO} {PROJECT_DIR}\n",
    "else:\n",
    "    print(f\"项目已存在: {PROJECT_DIR}\")\n",
    "    !cd {PROJECT_DIR} && git pull\n",
    "\n",
    "# 添加项目路径\n",
    "import sys\n",
    "sys.path.insert(0, PROJECT_DIR)\n",
    "\n",
    "print(f\"\\n项目结构:\")\n",
    "!ls -la {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"环境设置完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent训练数据格式定义\n",
    "# 数据格式: instruction + input -> output (JSON格式的思考过程和动作)\n",
    "\n",
    "TRAIN_DATA_EXAMPLES = [\n",
    "    {\n",
    "        \"instruction\": \"分析用户请求并决定下一步行动\",\n",
    "        \"input\": \"用户想查询北京明天的天气\",\n",
    "        \"output\": {\n",
    "            \"thought\": \"用户需要天气信息，我需要调用天气查询工具获取北京的天气数据\",\n",
    "            \"action\": \"weather_query\",\n",
    "            \"action_input\": {\"city\": \"北京\", \"date\": \"明天\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"根据工具执行结果生成最终回答\",\n",
    "        \"input\": \"工具返回: 北京明天晴天，温度15-25°C，空气质量良好\",\n",
    "        \"output\": {\n",
    "            \"thought\": \"已获取完整的天气信息，可以给出最终答案\",\n",
    "            \"action\": \"final_answer\",\n",
    "            \"action_input\": {\"answer\": \"北京明天天气晴朗，温度在15到25摄氏度之间，空气质量良好，适合外出活动。\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"分析用户请求并决定下一步行动\",\n",
    "        \"input\": \"计算 (123 + 456) * 2 的结果\",\n",
    "        \"output\": {\n",
    "            \"thought\": \"用户需要进行数学计算，调用计算器工具\",\n",
    "            \"action\": \"calculator\",\n",
    "            \"action_input\": {\"expression\": \"(123 + 456) * 2\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"分析用户请求并决定下一步行动\",\n",
    "        \"input\": \"现在几点了？\",\n",
    "        \"output\": {\n",
    "            \"thought\": \"用户想知道当前时间，调用时间工具\",\n",
    "            \"action\": \"datetime\",\n",
    "            \"action_input\": {\"format\": \"time\"}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"分析用户请求并决定下一步行动\",\n",
    "        \"input\": \"帮我搜索一下Python异步编程的最佳实践\",\n",
    "        \"output\": {\n",
    "            \"thought\": \"用户需要搜索信息，调用搜索工具\",\n",
    "            \"action\": \"search\",\n",
    "            \"action_input\": {\"query\": \"Python异步编程最佳实践\"}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"训练数据示例:\")\n",
    "print(json.dumps(TRAIN_DATA_EXAMPLES[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练数据集\n",
    "def generate_training_data(num_samples: int = 1000) -> List[Dict]:\n",
    "    \"\"\"生成Agent训练数据集\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # 工具定义\n",
    "    tools = {\n",
    "        \"weather_query\": {\n",
    "            \"params\": [\"city\", \"date\"],\n",
    "            \"cities\": [\"北京\", \"上海\", \"广州\", \"深圳\", \"杭州\", \"成都\", \"武汉\", \"西安\", \"南京\", \"苏州\"],\n",
    "            \"dates\": [\"今天\", \"明天\", \"后天\", \"本周\", \"下周\"]\n",
    "        },\n",
    "        \"calculator\": {\n",
    "            \"expressions\": [\n",
    "                \"{a} + {b}\",\n",
    "                \"{a} - {b}\",\n",
    "                \"{a} * {b}\",\n",
    "                \"{a} / {b}\",\n",
    "                \"({a} + {b}) * {c}\",\n",
    "                \"{a} ** 2 + {b}\",\n",
    "            ]\n",
    "        },\n",
    "        \"datetime\": {\n",
    "            \"formats\": [\"iso\", \"date\", \"time\", \"timestamp\"]\n",
    "        },\n",
    "        \"search\": {\n",
    "            \"queries\": [\n",
    "                \"Python教程\",\n",
    "                \"机器学习入门\",\n",
    "                \"深度学习框架\",\n",
    "                \"自然语言处理\",\n",
    "                \"数据可视化\",\n",
    "                \"API开发\",\n",
    "                \"数据库优化\",\n",
    "                \"前端框架\",\n",
    "                \"云服务部署\",\n",
    "                \"代码测试\"\n",
    "            ]\n",
    "        },\n",
    "        \"text_process\": {\n",
    "            \"operations\": [\"lowercase\", \"uppercase\", \"reverse\", \"word_count\", \"char_count\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    import random\n",
    "    random.seed(SEED)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        tool_type = list(tools.keys())[i % len(tools)]\n",
    "        \n",
    "        if tool_type == \"weather_query\":\n",
    "            city = random.choice(tools[\"weather_query\"][\"cities\"])\n",
    "            date = random.choice(tools[\"weather_query\"][\"dates\"])\n",
    "            data.append({\n",
    "                \"instruction\": \"分析用户请求并决定下一步行动\",\n",
    "                \"input\": f\"用户想查询{city}{date}的天气\",\n",
    "                \"output\": {\n",
    "                    \"thought\": f\"用户需要{city}{date}的天气信息，调用天气查询工具\",\n",
    "                    \"action\": \"weather_query\",\n",
    "                    \"action_input\": {\"city\": city, \"date\": date}\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        elif tool_type == \"calculator\":\n",
    "            a, b, c = random.randint(1, 100), random.randint(1, 100), random.randint(1, 10)\n",
    "            expr_template = random.choice(tools[\"calculator\"][\"expressions\"])\n",
    "            expr = expr_template.format(a=a, b=b, c=c)\n",
    "            data.append({\n",
    "                \"instruction\": \"分析用户请求并决定下一步行动\",\n",
    "                \"input\": f\"计算 {expr}\",\n",
    "                \"output\": {\n",
    "                    \"thought\": \"用户需要进行数学计算，调用计算器工具\",\n",
    "                    \"action\": \"calculator\",\n",
    "                    \"action_input\": {\"expression\": expr}\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        elif tool_type == \"datetime\":\n",
    "            fmt = random.choice(tools[\"datetime\"][\"formats\"])\n",
    "            questions = [\"现在几点了？\", \"今天日期是什么？\", \"给我当前时间\", \"显示当前时间戳\"]\n",
    "            data.append({\n",
    "                \"instruction\": \"分析用户请求并决定下一步行动\",\n",
    "                \"input\": random.choice(questions),\n",
    "                \"output\": {\n",
    "                    \"thought\": \"用户想知道当前时间信息，调用时间工具\",\n",
    "                    \"action\": \"datetime\",\n",
    "                    \"action_input\": {\"format\": fmt}\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        elif tool_type == \"search\":\n",
    "            query = random.choice(tools[\"search\"][\"queries\"])\n",
    "            data.append({\n",
    "                \"instruction\": \"分析用户请求并决定下一步行动\",\n",
    "                \"input\": f\"帮我搜索{query}相关内容\",\n",
    "                \"output\": {\n",
    "                    \"thought\": f\"用户需要搜索{query}相关信息，调用搜索工具\",\n",
    "                    \"action\": \"search\",\n",
    "                    \"action_input\": {\"query\": query}\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        elif tool_type == \"text_process\":\n",
    "            op = random.choice(tools[\"text_process\"][\"operations\"])\n",
    "            texts = [\"Hello World\", \"Python Programming\", \"AI Agent Core\", \"Machine Learning\"]\n",
    "            text = random.choice(texts)\n",
    "            data.append({\n",
    "                \"instruction\": \"分析用户请求并决定下一步行动\",\n",
    "                \"input\": f\"对文本 '{text}' 进行{op}处理\",\n",
    "                \"output\": {\n",
    "                    \"thought\": f\"用户需要对文本进行{op}处理，调用文本处理工具\",\n",
    "                    \"action\": \"text_process\",\n",
    "                    \"action_input\": {\"text\": text, \"operation\": op}\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # 添加最终答案示例\n",
    "    for i in range(num_samples // 5):\n",
    "        data.append({\n",
    "            \"instruction\": \"根据工具执行结果生成最终回答\",\n",
    "            \"input\": f\"工具返回: 操作成功完成，结果为 {random.randint(1, 1000)}\",\n",
    "            \"output\": {\n",
    "                \"thought\": \"已获取工具执行结果，可以给出最终答案\",\n",
    "                \"action\": \"final_answer\",\n",
    "                \"action_input\": {\"answer\": f\"操作已成功完成。根据查询结果，答案是 {random.randint(1, 1000)}。\"}\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "# 生成数据\n",
    "all_data = generate_training_data(2000)\n",
    "\n",
    "# 划分训练集和验证集\n",
    "split_idx = int(len(all_data) * 0.9)\n",
    "train_data = all_data[:split_idx]\n",
    "eval_data = all_data[split_idx:]\n",
    "\n",
    "print(f\"训练数据: {len(train_data)} 条\")\n",
    "print(f\"验证数据: {len(eval_data)} 条\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 格式化数据为训练格式\n",
    "def format_example(example: Dict) -> str:\n",
    "    \"\"\"将数据格式化为模型输入格式\"\"\"\n",
    "    output_str = json.dumps(example['output'], ensure_ascii=False)\n",
    "    return f\"\"\"<|im_start|>system\n",
    "你是一个智能AI助手，能够分析用户请求并选择合适的工具执行任务。\n",
    "你的输出必须是JSON格式：{{\"thought\": \"思考过程\", \"action\": \"工具名或final_answer\", \"action_input\": {{参数}}}}\n",
    "\n",
    "可用工具:\n",
    "- weather_query: 查询天气 (参数: city, date)\n",
    "- calculator: 数学计算 (参数: expression)\n",
    "- datetime: 获取时间 (参数: format)\n",
    "- search: 搜索信息 (参数: query)\n",
    "- text_process: 文本处理 (参数: text, operation)\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "{example['instruction']}\n",
    "\n",
    "{example['input']}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{output_str}<|im_end|>\"\"\"\n",
    "\n",
    "# 创建Dataset\n",
    "train_dataset = Dataset.from_list([\n",
    "    {\"text\": format_example(d)} for d in train_data\n",
    "])\n",
    "eval_dataset = Dataset.from_list([\n",
    "    {\"text\": format_example(d)} for d in eval_data\n",
    "])\n",
    "\n",
    "print(\"数据集创建完成!\")\n",
    "print(f\"\\n格式化示例:\")\n",
    "print(train_dataset[0]['text'][:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载Tokenizer\n",
    "print(f\"加载Tokenizer: {BASE_MODEL}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    trust_remote_code=True,\n",
    "    padding_side='right'\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"词表大小: {len(tokenizer)}\")\n",
    "print(f\"PAD Token: {tokenizer.pad_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 量化配置\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# 加载模型\n",
    "print(f\"加载模型: {BASE_MODEL}\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "print(f\"模型参数量: {model.num_parameters() / 1e9:.2f}B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA配置\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "print(\"\\nLoRA配置完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出目录\n",
    "OUTPUT_DIR = \"/content/outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=10,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    save_total_limit=3,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    run_name=f\"agent-core-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    ")\n",
    "\n",
    "print(\"训练参数配置完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=MAX_LENGTH,\n",
    "    packing=False,\n",
    ")\n",
    "\n",
    "print(\"Trainer创建完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "print(\"=\"*60)\n",
    "print(\"开始训练...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"训练完成!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n最终训练损失: {train_result.training_loss:.4f}\")\n",
    "print(f\"训练步数: {train_result.global_step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存LoRA权重\n",
    "lora_output_dir = os.path.join(OUTPUT_DIR, \"lora_weights\")\n",
    "trainer.model.save_pretrained(lora_output_dir)\n",
    "tokenizer.save_pretrained(lora_output_dir)\n",
    "\n",
    "print(f\"LoRA权重已保存: {lora_output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并LoRA权重\n",
    "from peft import PeftModel\n",
    "\n",
    "print(\"合并LoRA权重...\")\n",
    "\n",
    "# 重新加载基础模型\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# 加载并合并LoRA\n",
    "merged_model = PeftModel.from_pretrained(base_model, lora_output_dir)\n",
    "merged_model = merged_model.merge_and_unload()\n",
    "\n",
    "# 保存合并后的模型\n",
    "merged_output_dir = os.path.join(OUTPUT_DIR, \"merged_model\")\n",
    "merged_model.save_pretrained(merged_output_dir)\n",
    "tokenizer.save_pretrained(merged_output_dir)\n",
    "\n",
    "print(f\"合并模型已保存: {merged_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试推理\n",
    "def generate_response(model, tokenizer, prompt: str, max_new_tokens: int = 256) -> str:\n",
    "    \"\"\"生成模型响应\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# 测试用例\n",
    "test_cases = [\n",
    "    \"用户想查询上海今天的天气\",\n",
    "    \"计算 123 * 456\",\n",
    "    \"现在几点了？\",\n",
    "    \"帮我搜索Python教程\",\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"模型测试\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for test_input in test_cases:\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "你是一个智能AI助手，能够分析用户请求并选择合适的工具执行任务。\n",
    "你的输出必须是JSON格式：{{\"thought\": \"思考过程\", \"action\": \"工具名或final_answer\", \"action_input\": {{参数}}}}\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "分析用户请求并决定下一步行动\n",
    "\n",
    "{test_input}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "    \n",
    "    print(f\"\\n输入: {test_input}\")\n",
    "    response = generate_response(merged_model, tokenizer, prompt)\n",
    "    \n",
    "    # 提取assistant回复\n",
    "    if \"<|im_start|>assistant\" in response:\n",
    "        response = response.split(\"<|im_start|>assistant\")[-1].strip()\n",
    "    if \"<|im_end|>\" in response:\n",
    "        response = response.split(\"<|im_end|>\")[0].strip()\n",
    "    \n",
    "    print(f\"输出: {response}\")\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 上传到Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上传到Hugging Face (可选)\n",
    "if HF_TOKEN:\n",
    "    from huggingface_hub import HfApi, login\n",
    "    \n",
    "    print(f\"上传模型到: {HF_REPO_ID}\")\n",
    "    \n",
    "    login(token=HF_TOKEN)\n",
    "    \n",
    "    api = HfApi()\n",
    "    api.create_repo(repo_id=HF_REPO_ID, exist_ok=True)\n",
    "    api.upload_folder(\n",
    "        folder_path=merged_output_dir,\n",
    "        repo_id=HF_REPO_ID,\n",
    "        repo_type=\"model\",\n",
    "    )\n",
    "    \n",
    "    print(f\"模型已上传: https://huggingface.co/{HF_REPO_ID}\")\n",
    "else:\n",
    "    print(\"跳过上传 (未设置HF_TOKEN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打包模型\n",
    "import shutil\n",
    "\n",
    "zip_path = f\"{OUTPUT_DIR}/model_weights\"\n",
    "shutil.make_archive(zip_path, 'zip', merged_output_dir)\n",
    "\n",
    "print(f\"模型已打包: {zip_path}.zip\")\n",
    "print(f\"文件大小: {os.path.getsize(zip_path + '.zip') / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载模型\n",
    "from google.colab import files\n",
    "\n",
    "files.download(f\"{zip_path}.zip\")\n",
    "print(\"模型下载已开始...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 训练总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练总结\n",
    "summary = {\n",
    "    \"base_model\": BASE_MODEL,\n",
    "    \"github_repo\": GITHUB_REPO,\n",
    "    \"training_epochs\": NUM_EPOCHS,\n",
    "    \"train_loss\": train_result.training_loss,\n",
    "    \"global_step\": train_result.global_step,\n",
    "    \"lora_r\": LORA_R,\n",
    "    \"lora_alpha\": LORA_ALPHA,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"train_samples\": len(train_data),\n",
    "    \"eval_samples\": len(eval_data),\n",
    "    \"output_dir\": OUTPUT_DIR,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "# 保存总结\n",
    "with open(os.path.join(OUTPUT_DIR, \"training_summary.json\"), \"w\") as f:\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"训练总结\")\n",
    "print(\"=\"*60)\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"训练流程全部完成!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
